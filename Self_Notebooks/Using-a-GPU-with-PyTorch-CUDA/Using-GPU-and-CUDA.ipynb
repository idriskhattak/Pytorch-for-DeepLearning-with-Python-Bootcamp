{"cells":[{"cell_type":"markdown","metadata":{"id":"JlnEa0zW5pcO"},"source":["## IDRIS"]},{"cell_type":"markdown","metadata":{"id":"xVoiVWk1lm9T"},"source":["# What is CUDA?"]},{"cell_type":"markdown","metadata":{"id":"YPmNMWjXlm9U"},"source":["CUDA (Compute Unified Device Architecture) is a parallel computing platform and application programming interface (API) model created by NVIDIA. It enables developers to harness the computational power of NVIDIA GPUs (Graphics Processing Units) for general-purpose processing tasks beyond graphics rendering."]},{"cell_type":"markdown","metadata":{"id":"MCuMuEF7lm9Y"},"source":["# How do I know if I have CUDA available?"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2010,"status":"ok","timestamp":1707713581052,"user":{"displayName":"Idris Khan","userId":"04733233258715357493"},"user_tz":-300},"id":"rqxZUrpWlm9Z","outputId":"9f54570a-3b2c-49b9-9ad9-36118151b34f"},"outputs":[{"data":{"text/plain":["True"]},"execution_count":31,"metadata":{},"output_type":"execute_result"}],"source":["import torch\n","torch.cuda.is_available()"]},{"cell_type":"markdown","metadata":{"id":"EKFSfOYZlm9d"},"source":["# Using GPU and CUDA\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18,"status":"ok","timestamp":1707713587273,"user":{"displayName":"Idris Khan","userId":"04733233258715357493"},"user_tz":-300},"id":"RUgIBum2lm9e","outputId":"25def53e-8570-4674-c868-d94f15061852"},"outputs":[{"data":{"text/plain":["0"]},"execution_count":32,"metadata":{},"output_type":"execute_result"}],"source":["## Get Id of default device\n","torch.cuda.current_device()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"elapsed":17,"status":"ok","timestamp":1707713587274,"user":{"displayName":"Idris Khan","userId":"04733233258715357493"},"user_tz":-300},"id":"VEfAhVaFlm9f","outputId":"ad9cd37b-87b8-49f3-b1d5-0ff1c973729e"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'Tesla T4'"]},"execution_count":33,"metadata":{},"output_type":"execute_result"}],"source":["# 0\n","torch.cuda.get_device_name(0) # Get name device with ID '0'"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13,"status":"ok","timestamp":1707713587274,"user":{"displayName":"Idris Khan","userId":"04733233258715357493"},"user_tz":-300},"id":"X_CmzVa0lm9h","outputId":"fb68dada-6647-4be6-e94a-cc070debe8c3"},"outputs":[{"data":{"text/plain":["17107456"]},"execution_count":34,"metadata":{},"output_type":"execute_result"}],"source":["# Returns the current GPU memory usage by\n","# tensors in bytes for a given device\n","torch.cuda.memory_allocated()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11,"status":"ok","timestamp":1707713587275,"user":{"displayName":"Idris Khan","userId":"04733233258715357493"},"user_tz":-300},"id":"sE1HL-q6lm9i","outputId":"55ca9d25-7169-4faf-e888-dd950e5ffad9"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/cuda/memory.py:444: FutureWarning: torch.cuda.memory_cached has been renamed to torch.cuda.memory_reserved\n","  warnings.warn(\n"]},{"data":{"text/plain":["23068672"]},"execution_count":35,"metadata":{},"output_type":"execute_result"}],"source":["# Returns the current GPU memory managed by the\n","# caching allocator in bytes for a given device\n","torch.cuda.memory_cached()"]},{"cell_type":"markdown","metadata":{"id":"8pQV1DM1lm9i"},"source":["# Using CUDA instead of CPU"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ruYL5B1Dlm9j"},"outputs":[],"source":["# CPU\n","a = torch.FloatTensor([1.,2.])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1707713592214,"user":{"displayName":"Idris Khan","userId":"04733233258715357493"},"user_tz":-300},"id":"DT-Tvg5Ilm9j","outputId":"db6cd03e-f803-4c2b-9838-b34112a1d7c0"},"outputs":[{"data":{"text/plain":["tensor([1., 2.])"]},"execution_count":37,"metadata":{},"output_type":"execute_result"}],"source":["a"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1707713592214,"user":{"displayName":"Idris Khan","userId":"04733233258715357493"},"user_tz":-300},"id":"nb0J8b-1lm9k","outputId":"768df412-3959-45b8-edd0-af8f608ffb94"},"outputs":[{"data":{"text/plain":["device(type='cpu')"]},"execution_count":38,"metadata":{},"output_type":"execute_result"}],"source":["a.device"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qv5WuOA2lm9l"},"outputs":[],"source":["# GPU\n","a = torch.FloatTensor([1., 2.]).cuda()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1707713594086,"user":{"displayName":"Idris Khan","userId":"04733233258715357493"},"user_tz":-300},"id":"VxmxZ_LPlm9m","outputId":"3ef2ae73-cfd3-45d3-dccf-04439a06bd75"},"outputs":[{"data":{"text/plain":["device(type='cuda', index=0)"]},"execution_count":40,"metadata":{},"output_type":"execute_result"}],"source":["a.device"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1707713595709,"user":{"displayName":"Idris Khan","userId":"04733233258715357493"},"user_tz":-300},"id":"uwY5d-30lm9m","outputId":"e219e946-f076-4495-e8a8-fb5ee521a57a"},"outputs":[{"data":{"text/plain":["17107456"]},"execution_count":41,"metadata":{},"output_type":"execute_result"}],"source":["torch.cuda.memory_allocated()"]},{"cell_type":"markdown","metadata":{"id":"e4LWvZO3lm9n"},"source":["## Defining our Model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OiVt86WLlm9o"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torchvision import datasets, transforms\n","from torch.utils.data import Dataset, DataLoader\n","from sklearn.model_selection import train_test_split"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BiG8R6D_lm9o"},"outputs":[],"source":["class Model(nn.Module):\n","    def __init__(self, in_features=4, h1=8, h2=9, out_features=3):\n","        super().__init__()\n","        self.fc1 = nn.Linear(in_features,h1)    # input layer\n","        self.fc2 = nn.Linear(h1, h2)            # hidden layer\n","        self.out = nn.Linear(h2, out_features)  # output layer\n","\n","    def forward(self, x):\n","        x = F.relu(self.fc1(x))\n","        x = F.relu(self.fc2(x))\n","        x = self.out(x)\n","        return x"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hirSHOCnlm9p"},"outputs":[],"source":["model = Model()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1707717410143,"user":{"displayName":"Idris Khan","userId":"04733233258715357493"},"user_tz":-300},"id":"ulO-YHvqlm9q","outputId":"1d9abf2d-5a56-44e2-a2f5-13a2ff9545dd"},"outputs":[{"data":{"text/plain":["False"]},"execution_count":180,"metadata":{},"output_type":"execute_result"}],"source":["# Checking if our model is on cuda or not.\n","next(model.parameters()).is_cuda"]},{"cell_type":"markdown","metadata":{"id":"--NMZ6E0q3eS"},"source":["Will be using a very simple MNIST dataset just to demonstrate between CPU and GPU."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hFVEujSisszv"},"outputs":[],"source":["transform = transforms.ToTensor()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nGN8IzIytK2E"},"outputs":[],"source":["train_data = datasets.MNIST(root='../Data', train=True, download=True, transform= transform)\n","test_data = datasets.MNIST(root='../Data', train=False, download=True, transform=transform)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"R-F75FvetbGv"},"outputs":[],"source":["train_loader = DataLoader(train_data, batch_size= 10, shuffle=True)\n","test_loader = DataLoader(test_data, batch_size= 10, shuffle=False)"]},{"cell_type":"markdown","metadata":{"id":"lkBcxBJfthGf"},"source":["  # Defining model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JbVz6n5xtmmf"},"outputs":[],"source":["class ConvolutionalNetwork(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.conv1 = nn.Conv2d(1, 6, 3, 1)\n","        self.conv2 = nn.Conv2d(6, 16, 3, 1)\n","        self.fc1 = nn.Linear(5*5*16, 120)\n","        self.fc2 = nn.Linear(120, 84)\n","        self.fc3 = nn.Linear(84,10)\n","\n","    def forward(self, X):\n","        X = F.relu(self.conv1(X))\n","        X = F.max_pool2d(X, 2, 2)\n","        X = F.relu(self.conv2(X))\n","        X = F.max_pool2d(X, 2, 2)\n","        X = X.view(-1, 5*5*16)\n","        X = F.relu(self.fc1(X))\n","        X = F.relu(self.fc2(X))\n","        X = self.fc3(X)\n","        return F.log_softmax(X, dim=1)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1707717421332,"user":{"displayName":"Idris Khan","userId":"04733233258715357493"},"user_tz":-300},"id":"8DDXxx2-vHMD","outputId":"064673fe-a0c0-4438-ae37-efb6d1879844"},"outputs":[{"data":{"text/plain":["ConvolutionalNetwork(\n","  (conv1): Conv2d(1, 6, kernel_size=(3, 3), stride=(1, 1))\n","  (conv2): Conv2d(6, 16, kernel_size=(3, 3), stride=(1, 1))\n","  (fc1): Linear(in_features=400, out_features=120, bias=True)\n","  (fc2): Linear(in_features=120, out_features=84, bias=True)\n","  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",")"]},"execution_count":186,"metadata":{},"output_type":"execute_result"}],"source":["model = ConvolutionalNetwork()\n","model"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1707717427075,"user":{"displayName":"Idris Khan","userId":"04733233258715357493"},"user_tz":-300},"id":"z6xbiTIdvROu","outputId":"6a494b52-84f0-4b01-a30a-be89b61993ba"},"outputs":[{"data":{"text/plain":["False"]},"execution_count":187,"metadata":{},"output_type":"execute_result"}],"source":["# Checking if our model is on cuda or not.\n","next(model.parameters()).is_cuda"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1woPMVpSvK5c"},"outputs":[],"source":["# Defining loss and criterion\n","criterion = nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"]},{"cell_type":"markdown","metadata":{"id":"e0Ex3pHevWxW"},"source":["# Training our Model"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":66478,"status":"ok","timestamp":1707717498985,"user":{"displayName":"Idris Khan","userId":"04733233258715357493"},"user_tz":-300},"id":"v1STRRh3vWIC","outputId":"c9ca0d6b-2d7c-403c-f82d-f36855a66906"},"outputs":[{"name":"stdout","output_type":"stream","text":["epoch:  1  batch:  600 [  6000/60000]  loss: 0.37270087  accuracy:  73.500%\n","epoch:  1  batch: 1200 [ 12000/60000]  loss: 0.15206459  accuracy:  82.833%\n","epoch:  1  batch: 1800 [ 18000/60000]  loss: 0.01752903  accuracy:  86.661%\n","epoch:  1  batch: 2400 [ 24000/60000]  loss: 0.05838161  accuracy:  88.821%\n","epoch:  1  batch: 3000 [ 30000/60000]  loss: 0.02061462  accuracy:  90.173%\n","epoch:  1  batch: 3600 [ 36000/60000]  loss: 0.01586456  accuracy:  91.228%\n","epoch:  1  batch: 4200 [ 42000/60000]  loss: 0.01075920  accuracy:  92.019%\n","epoch:  1  batch: 4800 [ 48000/60000]  loss: 0.13801089  accuracy:  92.627%\n","epoch:  1  batch: 5400 [ 54000/60000]  loss: 0.01024230  accuracy:  93.133%\n","epoch:  1  batch: 6000 [ 60000/60000]  loss: 0.13038364  accuracy:  93.560%\n","epoch:  2  batch:  600 [  6000/60000]  loss: 0.03631741  accuracy:  97.717%\n","epoch:  2  batch: 1200 [ 12000/60000]  loss: 0.01364149  accuracy:  97.675%\n","epoch:  2  batch: 1800 [ 18000/60000]  loss: 0.02211459  accuracy:  97.678%\n","epoch:  2  batch: 2400 [ 24000/60000]  loss: 0.01452830  accuracy:  97.729%\n","epoch:  2  batch: 3000 [ 30000/60000]  loss: 0.36127701  accuracy:  97.793%\n","epoch:  2  batch: 3600 [ 36000/60000]  loss: 0.00113225  accuracy:  97.814%\n","epoch:  2  batch: 4200 [ 42000/60000]  loss: 0.03027896  accuracy:  97.817%\n","epoch:  2  batch: 4800 [ 48000/60000]  loss: 0.44510245  accuracy:  97.829%\n","epoch:  2  batch: 5400 [ 54000/60000]  loss: 0.00496268  accuracy:  97.859%\n","epoch:  2  batch: 6000 [ 60000/60000]  loss: 0.16848764  accuracy:  97.867%\n","\n","Duration: 67 seconds\n"]}],"source":["import time\n","\n","start_time = time.time()\n","\n","epochs = 2\n","train_losses = []\n","test_losses = []\n","train_correct = []\n","test_correct = []\n","\n","for i in range(epochs):\n","    trn_corr = 0\n","    tst_corr = 0\n","\n","    # Run the training batches\n","    for b, (X_train, y_train) in enumerate(train_loader):\n","        b += 1\n","\n","\n","        # Apply the model\n","        y_pred = model(X_train)  # Apply the model on GPU\n","        loss = criterion(y_pred, y_train)\n","\n","        # Tally the number of correct predictions\n","        predicted = torch.max(y_pred, 1)[1]  # No need for .data here\n","        batch_corr = (predicted == y_train).sum().item()  # Get the number of correct predictions\n","        trn_corr += batch_corr\n","\n","        # Update parameters\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","        # Print interim results\n","        if b % 600 == 0:\n","            print(f'epoch: {i+1:2}  batch: {b:4} [{10 * b:6}/60000]  loss: {loss.item():10.8f}  accuracy: {trn_corr * 100 / (10 * b):7.3f}%')\n","\n","    train_losses.append(loss)\n","    train_correct.append(trn_corr)\n","\n","    # Run the testing batches\n","    with torch.no_grad():\n","        for b, (X_test, y_test) in enumerate(test_loader):\n","\n","            # Apply the model\n","            y_val = model(X_test)\n","\n","            # Tally the number of correct predictions\n","            predicted = torch.max(y_val, 1)[1]\n","            tst_corr += (predicted == y_test).sum().item()\n","\n","    # Calculate the test loss after processing all test batches\n","    loss = criterion(y_val, y_test)\n","    test_losses.append(loss)\n","    test_correct.append(tst_corr)\n","\n","print(f'\\nDuration: {time.time() - start_time:.0f} seconds')  # Print the time elapsed\n"]},{"cell_type":"markdown","metadata":{"id":"ZMyLPO8mwsAc"},"source":["# Now using CUDA on MNIST"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uHf5dIi_xU-T"},"outputs":[],"source":["gpumodel = ConvolutionalNetwork().cuda()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1707717506241,"user":{"displayName":"Idris Khan","userId":"04733233258715357493"},"user_tz":-300},"id":"KEP9Scq6xmVR","outputId":"be7bbac0-e8da-4b8d-8872-870cdda8a47d"},"outputs":[{"data":{"text/plain":["True"]},"execution_count":191,"metadata":{},"output_type":"execute_result"}],"source":["# Checking if our model is on cuda or not.\n","next(gpumodel.parameters()).is_cuda"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EJTwJHP7xnuC"},"outputs":[],"source":["# Defining loss and criterion\n","criterion = nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(gpumodel.parameters(), lr=0.001)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":47523,"status":"ok","timestamp":1707717569009,"user":{"displayName":"Idris Khan","userId":"04733233258715357493"},"user_tz":-300},"id":"Ve5z4bwsxtHZ","outputId":"5c08294e-df71-4f0e-91c7-8fd9fcf61833"},"outputs":[{"name":"stdout","output_type":"stream","text":["epoch:  1  batch:  600 [  6000/60000]  loss: 0.02661047  accuracy:  80.267%\n","epoch:  1  batch: 1200 [ 12000/60000]  loss: 0.03233250  accuracy:  87.067%\n","epoch:  1  batch: 1800 [ 18000/60000]  loss: 0.07894491  accuracy:  89.961%\n","epoch:  1  batch: 2400 [ 24000/60000]  loss: 0.02530557  accuracy:  91.504%\n","epoch:  1  batch: 3000 [ 30000/60000]  loss: 0.23879036  accuracy:  92.460%\n","epoch:  1  batch: 3600 [ 36000/60000]  loss: 0.00357001  accuracy:  93.189%\n","epoch:  1  batch: 4200 [ 42000/60000]  loss: 0.03443167  accuracy:  93.762%\n","epoch:  1  batch: 4800 [ 48000/60000]  loss: 0.22139096  accuracy:  94.188%\n","epoch:  1  batch: 5400 [ 54000/60000]  loss: 0.01990363  accuracy:  94.594%\n","epoch:  1  batch: 6000 [ 60000/60000]  loss: 0.02439185  accuracy:  94.882%\n","epoch:  2  batch:  600 [  6000/60000]  loss: 0.10189235  accuracy:  97.983%\n","epoch:  2  batch: 1200 [ 12000/60000]  loss: 0.00636857  accuracy:  97.900%\n","epoch:  2  batch: 1800 [ 18000/60000]  loss: 0.00662791  accuracy:  97.950%\n","epoch:  2  batch: 2400 [ 24000/60000]  loss: 0.06784761  accuracy:  97.967%\n","epoch:  2  batch: 3000 [ 30000/60000]  loss: 0.00465672  accuracy:  98.040%\n","epoch:  2  batch: 3600 [ 36000/60000]  loss: 0.04302145  accuracy:  98.006%\n","epoch:  2  batch: 4200 [ 42000/60000]  loss: 0.00036550  accuracy:  98.050%\n","epoch:  2  batch: 4800 [ 48000/60000]  loss: 0.45378572  accuracy:  98.067%\n","epoch:  2  batch: 5400 [ 54000/60000]  loss: 0.04161624  accuracy:  98.063%\n","epoch:  2  batch: 6000 [ 60000/60000]  loss: 0.00428431  accuracy:  98.062%\n","\n","Duration: 47 seconds\n"]}],"source":["import time\n","\n","start_time = time.time()\n","\n","epochs = 2\n","train_losses = []\n","test_losses = []\n","train_correct = []\n","test_correct = []\n","\n","for i in range(epochs):\n","    trn_corr = 0\n","    tst_corr = 0\n","\n","    # Run the training batches\n","    for b, (X_train, y_train) in enumerate(train_loader):\n","        b += 1\n","\n","        # Move data to GPU\n","        X_train = X_train.cuda()\n","        y_train = y_train.cuda()\n","\n","        # Apply the model\n","        y_pred = gpumodel(X_train)  # Apply the model on GPU\n","        loss = criterion(y_pred, y_train)\n","\n","        # Tally the number of correct predictions\n","        predicted = torch.max(y_pred, 1)[1]  # No need for .data here\n","        batch_corr = (predicted == y_train).sum().item()  # Get the number of correct predictions\n","        trn_corr += batch_corr\n","\n","        # Update parameters\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","        # Print interim results\n","        if b % 600 == 0:\n","            print(f'epoch: {i+1:2}  batch: {b:4} [{10 * b:6}/60000]  loss: {loss.item():10.8f}  accuracy: {trn_corr * 100 / (10 * b):7.3f}%')\n","\n","    train_losses.append(loss)\n","    train_correct.append(trn_corr)\n","\n","    # Run the testing batches\n","    with torch.no_grad():\n","        for b, (X_test, y_test) in enumerate(test_loader):\n","            # Move data to GPU\n","            X_test = X_test.cuda()\n","            y_test = y_test.cuda()\n","\n","            # Apply the model\n","            y_val = gpumodel(X_test)\n","\n","            # Tally the number of correct predictions\n","            predicted = torch.max(y_val, 1)[1]\n","            tst_corr += (predicted == y_test).sum().item()\n","\n","    # Calculate the test loss after processing all test batches\n","    loss = criterion(y_val, y_test)\n","    test_losses.append(loss)\n","    test_correct.append(tst_corr)\n","\n","print(f'\\nDuration: {time.time() - start_time:.0f} seconds')  # Print the time elapsed\n"]},{"cell_type":"markdown","metadata":{},"source":["Summary:\n","In this demonstration, we compared the performance of training a deep learning model on CPU and CUDA (GPU). The CPU execution took approximately 67 seconds, while the CUDA execution took approximately 47 seconds. This highlights the significant speedup achieved by utilizing the GPU for training deep learning models."]},{"cell_type":"markdown","metadata":{},"source":["# End"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"}},"nbformat":4,"nbformat_minor":0}
